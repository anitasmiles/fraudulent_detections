{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Underbalanced Code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9o_jJjw9Ysnt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'> FRAUD DETECTION - UNDERBALANCE </Bold></center></font>\n"
      ]
    },
    {
      "metadata": {
        "id": "sBofcGpSYsnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour\n",
        "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
        "from imblearn.under_sampling import ClusterCentroids\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, auc, precision_recall_curve,roc_curve, accuracy_score, cohen_kappa_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.gridspec as gridspec\n",
        "from sklearn import tree\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dMz8to2DYsnx",
        "colab_type": "code",
        "outputId": "217ef9de-9b92-4e07-fa73-8cf1c1642f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "df.head()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...         V21       V22       V23       V24  \\\n",
              "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
              "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
              "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
              "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
              "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
              "\n",
              "        V25       V26       V27       V28  Amount  Class  \n",
              "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "hyXkmUvPYsoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Didnt do this for underbalanced\n",
        "# Based on observation of data overlap above, try out a second dataset with redunancies removed\n",
        "# df= df.drop(['V28','V27','V23','V8'], axis =1)\n",
        "# Later - can re run everything after running the following line\n",
        "#data = clean_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tzo1a6h9Ysoc",
        "colab_type": "code",
        "outputId": "343ab6b9-1afd-4f1f-e27b-28458148bb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.array(df.iloc[:, df.columns != 'Class'])\n",
        "y = np.array(df.iloc[:, df.columns == 'Class'])\n",
        "print('Shape of X: {}'.format(X.shape))\n",
        "print('Shape of y: {}'.format(y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X: (284807, 30)\n",
            "Shape of y: (284807, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wFFEoSWFYsof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'> SPLITTING DATA </Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "rs1FHCrkYsog",
        "colab_type": "code",
        "outputId": "010b56bc-40c0-4b3b-e4ed-99e631de7b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#splitting data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
        "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
        "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
        "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
        "\n",
        "print(np.unique(y_train, return_counts=True))\n",
        "np.unique(y_test, return_counts=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number transactions X_train dataset:  (199364, 30)\n",
            "Number transactions y_train dataset:  (199364, 1)\n",
            "Number transactions X_test dataset:  (85443, 30)\n",
            "Number transactions y_test dataset:  (85443, 1)\n",
            "(array([0, 1]), array([199019,    345]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([85296,   147]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "oUywg8_ZYso5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'>APPLYING RANDOM & INFORMATIVE UNDERSAMPLING TECHNIQUES TO DERIVE 6 UNDERSAMPLED DATASETS</Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "hqz7UFAdYso5",
        "colab_type": "code",
        "outputId": "0e07557a-85ae-4b5e-e4e9-5af316e6a238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "# Applying Random UnderSampling (50% of Minority Class) - RUS50\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy=1,random_state=5)\n",
        "X_train_rus50, y_train_rus50 = rus.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After UnderSampling, the shape of train_X: {}'.format(X_train_rus50.shape))\n",
        "print('After UnderSampling, the shape of train_y: {} \\n'.format(y_train_rus50.shape))\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_rus50==1)))\n",
        "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_train_rus50==0)))                                                                   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before UnderSampling, counts of label '1': [345]\n",
            "Before UnderSampling, counts of label '0': [199019] \n",
            "\n",
            "After UnderSampling, the shape of train_X: (690, 30)\n",
            "After UnderSampling, the shape of train_y: (690,) \n",
            "\n",
            "After UnderSampling, counts of label '1': 345\n",
            "After UnderSampling, counts of label '0': 345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "77XVpDSDYso7",
        "colab_type": "code",
        "outputId": "e4d7b0db-6784-4ae9-f1c3-62eff3b678a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "# Applying Random UnderSampling (10% of Minority Class) - RUS10\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy=0.10, random_state=100)\n",
        "X_train_rus10, y_train_rus10 = rus.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After UnderSampling, the shape of train_X: {}'.format(X_train_rus10.shape))\n",
        "print('After UnderSampling, the shape of train_y: {} \\n'.format(y_train_rus10.shape))\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_rus10==1)))\n",
        "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_train_rus10==0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before UnderSampling, counts of label '1': [345]\n",
            "Before UnderSampling, counts of label '0': [199019] \n",
            "\n",
            "After UnderSampling, the shape of train_X: (3795, 30)\n",
            "After UnderSampling, the shape of train_y: (3795,) \n",
            "\n",
            "After UnderSampling, counts of label '1': 345\n",
            "After UnderSampling, counts of label '0': 3450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "99iNfstHYso9",
        "colab_type": "code",
        "outputId": "80411565-32b0-4d9b-eb85-f38e47d8352c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "# Applying Random UnderSampling (1% of Minority Class) - RUS1\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy=0.01, random_state=100)\n",
        "X_train_rus1, y_train_rus1 = rus.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After UnderSampling, the shape of train_X: {}'.format(X_train_rus10.shape))\n",
        "print('After UnderSampling, the shape of train_y: {} \\n'.format(y_train_rus1.shape))\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_rus1==1)))\n",
        "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_train_rus1==0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before UnderSampling, counts of label '1': [345]\n",
            "Before UnderSampling, counts of label '0': [199019] \n",
            "\n",
            "After UnderSampling, the shape of train_X: (3795, 30)\n",
            "After UnderSampling, the shape of train_y: (34845,) \n",
            "\n",
            "After UnderSampling, counts of label '1': 345\n",
            "After UnderSampling, counts of label '0': 34500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AsP80gSKqbQW",
        "colab_type": "code",
        "outputId": "419d09d2-c83c-4a06-8295-affd7a31ef48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "# Applying Informative UnderSampling (Edited Nearest Neighbours) - ENN\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "enn = EditedNearestNeighbours(sampling_strategy='auto')\n",
        "X_train_enn, y_train_enn = enn.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After UnderSampling, the shape of train_X: {}'.format(X_train_enn.shape))\n",
        "print('After UnderSampling, the shape of train_y: {} \\n'.format(y_train_enn.shape))\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_enn==1)))\n",
        "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_train_enn==0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before UnderSampling, counts of label '1': [345]\n",
            "Before UnderSampling, counts of label '0': [199019] \n",
            "\n",
            "After UnderSampling, the shape of train_X: (199031, 30)\n",
            "After UnderSampling, the shape of train_y: (199031,) \n",
            "\n",
            "After UnderSampling, counts of label '1': 345\n",
            "After UnderSampling, counts of label '0': 198686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yyYir26g2iUn",
        "colab_type": "code",
        "outputId": "63f17b97-1d68-4d7e-ef66-5bc2481375b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "# Applying Informative UnderSampling (Condensed Nearest Neighbour) - CNN\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "cnn = CondensedNearestNeighbour(sampling_strategy='auto', random_state = 17)\n",
        "X_train_cnn, y_train_cnn = cnn.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After UnderSampling, the shape of train_X: {}'.format(X_train_cnn.shape))\n",
        "print('After UnderSampling, the shape of train_y: {} \\n'.format(y_train_cnn.shape))\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_cnn==1)))\n",
        "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_train_cnn==0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before UnderSampling, counts of label '1': [345]\n",
            "Before UnderSampling, counts of label '0': [199019] \n",
            "\n",
            "After UnderSampling, the shape of train_X: (2142, 30)\n",
            "After UnderSampling, the shape of train_y: (2142,) \n",
            "\n",
            "After UnderSampling, counts of label '1': 345\n",
            "After UnderSampling, counts of label '0': 1797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LAndTWwAqbCy",
        "colab_type": "code",
        "outputId": "ff09dfce-c47d-4332-c3df-bb1628e72a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "# Applying Informative UnderSampling (Neighbourhood Cleaning Rule) - NCL\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "ncl = NeighbourhoodCleaningRule(sampling_strategy='auto')\n",
        "X_train_ncl, y_train_ncl = ncl.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After UnderSampling, the shape of train_X: {}'.format(X_train_ncl.shape))\n",
        "print('After UnderSampling, the shape of train_y: {} \\n'.format(y_train_ncl.shape))\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_ncl==1)))\n",
        "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_train_ncl==0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before UnderSampling, counts of label '1': [345]\n",
            "Before UnderSampling, counts of label '0': [199019] \n",
            "\n",
            "After UnderSampling, the shape of train_X: (198486, 30)\n",
            "After UnderSampling, the shape of train_y: (198486,) \n",
            "\n",
            "After UnderSampling, counts of label '1': 345\n",
            "After UnderSampling, counts of label '0': 198141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bR8C5Fd-Yso_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'>SVM FOR UNDERBALANCED DATASETS</Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "IXG7DLaXYspA",
        "colab_type": "code",
        "outputId": "c629afd1-abe3-406e-eeed-976f0fed2ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm = svm.LinearSVC(C=1.0, dual=False)\n",
        "sv=lsvm.fit(X_train_rus50, y_train_rus50.ravel())\n",
        "y_pred_rus50_svm = lsvm.predict(X_test)\n",
        "print (sv)\n",
        "\n",
        "print('Confusion Matrix for SVM on RUS50 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus50_svm))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus50_svm))\n",
        "print(classification_report(y_test, y_pred_rus50_svm))\n",
        "# plot_confusion_matrix(y_test, y_pred)\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus50_svm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n",
            "Confusion Matrix for SVM on RUS50 Dataset\n",
            "[[82718  2578]\n",
            " [   13   134]]\n",
            "Accuracy: 0.9696756902262327\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     85296\n",
            "           1       0.05      0.91      0.09       147\n",
            "\n",
            "   micro avg       0.97      0.97      0.97     85443\n",
            "   macro avg       0.52      0.94      0.54     85443\n",
            "weighted avg       1.00      0.97      0.98     85443\n",
            "\n",
            "Kappa Score: 0.09077137318584805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KIUbmSGUYspE",
        "colab_type": "code",
        "outputId": "eb3fad3d-789d-4ca0-c155-b28629041a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm = svm.LinearSVC(C=1.0, dual=False)\n",
        "sv=lsvm.fit(X_train_rus10, y_train_rus10.ravel())\n",
        "y_pred_rus10_svm = lsvm.predict(X_test)\n",
        "print (sv)\n",
        "\n",
        "print('Confusion Matrix for SVM on RUS10 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus10_svm))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus10_svm))\n",
        "print(classification_report(y_test, y_pred_rus10_svm))\n",
        "# plot_confusion_matrix(y_test, y_pred)\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus10_svm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n",
            "Confusion Matrix for SVM on RUS10 Dataset\n",
            "[[85078   218]\n",
            " [   40   107]]\n",
            "Accuracy: 0.9969804431024192\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.33      0.73      0.45       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.66      0.86      0.73     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.4520916948260042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5s6gF44HYspI",
        "colab_type": "code",
        "outputId": "ef4d7c80-856c-4925-9cc4-ba68616bb174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm = svm.LinearSVC(C=1.0, dual=False)\n",
        "sv=lsvm.fit(X_train_rus1, y_train_rus1.ravel())\n",
        "y_pred_rus1_svm = lsvm.predict(X_test)\n",
        "print (sv)\n",
        "\n",
        "print('Confusion Matrix for SVM on RUS1 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus1_svm))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus1_svm))\n",
        "print(classification_report(y_test, y_pred_rus1_svm))\n",
        "# plot_confusion_matrix(y_test, y_pred)\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus1_svm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n",
            "Confusion Matrix for SVM on RUS1 Dataset\n",
            "[[85163   133]\n",
            " [   40   107]]\n",
            "Accuracy: 0.9979752583593741\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.45      0.73      0.55       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.72      0.86      0.78     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.5520156288598568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "58266d30-3550-4f72-dace-ee638da5c883",
        "id": "h0pxn0oNOF4x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm = svm.LinearSVC(C=1.0, dual=False)\n",
        "sv=lsvm.fit(X_train_enn, y_train_enn.ravel())\n",
        "y_pred_enn_svm = lsvm.predict(X_test)\n",
        "print (sv)\n",
        "\n",
        "print('Confusion Matrix for SVM on ENN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_enn_svm))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_enn_svm))\n",
        "print(classification_report(y_test, y_pred_enn_svm))\n",
        "# plot_confusion_matrix(y_test, y_pred)\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_enn_svm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n",
            "Confusion Matrix for SVM on ENN Dataset\n",
            "[[85283    13]\n",
            " [   75    72]]\n",
            "Accuracy: 0.9989700736163291\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.85      0.49      0.62       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.92      0.74      0.81     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.6202108660028955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "1e924257-dbf2-4530-f212-3a5e5f2c4335",
        "id": "uqi51DbMOGfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm = svm.LinearSVC(C=1.0, dual=False)\n",
        "sv=lsvm.fit(X_train_cnn, y_train_cnn.ravel())\n",
        "y_pred_cnn_svm = lsvm.predict(X_test)\n",
        "print (sv)\n",
        "\n",
        "print('Confusion Matrix for SVM on CNN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_cnn_svm))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_cnn_svm))\n",
        "print(classification_report(y_test, y_pred_cnn_svm))\n",
        "# plot_confusion_matrix(y_test, y_pred)\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_cnn_svm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n",
            "Confusion Matrix for SVM on CNN Dataset\n",
            "[[85086   210]\n",
            " [   38   109]]\n",
            "Accuracy: 0.9970974801914727\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.34      0.74      0.47       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.67      0.87      0.73     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.4665546499765423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9f4d31b7-c489-4bf8-8e30-4abb6638c436",
        "id": "TxBRVn6TOIjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm = svm.LinearSVC(C=1.0, dual=False)\n",
        "sv=lsvm.fit(X_train_ncl, y_train_ncl.ravel())\n",
        "y_pred_ncl_svm = lsvm.predict(X_test)\n",
        "print (sv)\n",
        "\n",
        "print('Confusion Matrix for SVM on NCL Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_ncl_svm))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_ncl_svm))\n",
        "print(classification_report(y_test, y_pred_ncl_svm))\n",
        "# plot_confusion_matrix(y_test, y_pred)\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_ncl_svm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n",
            "Confusion Matrix for SVM on NCL Dataset\n",
            "[[85285    11]\n",
            " [   55    92]]\n",
            "Accuracy: 0.9992275552122467\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.89      0.63      0.74       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.95      0.81      0.87     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.7356252099110061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u8Ju-xa1YspK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'>NAIVE BAYES FOR UNDERBALANCED DATASETS</Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "Cso_jktyYspK",
        "colab_type": "code",
        "outputId": "70d57dee-01b8-417e-da40-43bd36d2d1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "model=classifier.fit(X_train_rus50, y_train_rus50.ravel())\n",
        "y_pred_rus50_nb = model.predict(X_test)\n",
        "print (model)\n",
        "\n",
        "print('Confusion Matrix for Naive Bayes on RUS50 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus50_nb))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus50_nb))\n",
        "print(classification_report(y_test, y_pred_rus50_nb))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus50_nb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "Confusion Matrix for Naive Bayes on RUS50 Dataset\n",
            "[[84007  1289]\n",
            " [   43   104]]\n",
            "Accuracy: 0.984410659738071\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     85296\n",
            "           1       0.07      0.71      0.14       147\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     85443\n",
            "   macro avg       0.54      0.85      0.56     85443\n",
            "weighted avg       1.00      0.98      0.99     85443\n",
            "\n",
            "Kappa Score: 0.13236446998512907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3aad6da1-66f1-40d2-b2b0-eb073d466390",
        "id": "gveK8a4hTZym",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "model=classifier.fit(X_train_rus10, y_train_rus10.ravel())\n",
        "y_pred_rus10_nb = model.predict(X_test)\n",
        "print (model)\n",
        "\n",
        "print('Confusion Matrix for Naive Bayes on RUS10 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus10_nb))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus10_nb))\n",
        "print(classification_report(y_test, y_pred_rus10_nb))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus10_nb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "Confusion Matrix for Naive Bayes on RUS10 Dataset\n",
            "[[84696   600]\n",
            " [   48    99]]\n",
            "Accuracy: 0.9924159966293319\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     85296\n",
            "           1       0.14      0.67      0.23       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.57      0.83      0.62     85443\n",
            "weighted avg       1.00      0.99      0.99     85443\n",
            "\n",
            "Kappa Score: 0.2318587235453765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e38795d9-cd74-4609-ed1e-9d247eb92084",
        "id": "PTfb0JFeTaDu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "model=classifier.fit(X_train_rus1, y_train_rus1.ravel())\n",
        "y_pred_rus1_nb = model.predict(X_test)\n",
        "print (model)\n",
        "\n",
        "print('Confusion Matrix for Naive Bayes on RUS1 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus1_nb))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus1_nb))\n",
        "print(classification_report(y_test, y_pred_rus1_nb))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus1_nb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "Confusion Matrix for Naive Bayes on RUS1 Dataset\n",
            "[[84703   593]\n",
            " [   49    98]]\n",
            "Accuracy: 0.9924862188827639\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     85296\n",
            "           1       0.14      0.67      0.23       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.57      0.83      0.62     85443\n",
            "weighted avg       1.00      0.99      0.99     85443\n",
            "\n",
            "Kappa Score: 0.23171034851357342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "56799729-f81c-42ca-f847-90fee867a086",
        "id": "NDKDdP6fTaPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "model=classifier.fit(X_train_enn, y_train_enn.ravel())\n",
        "y_pred_enn_nb = model.predict(X_test)\n",
        "print (model)\n",
        "\n",
        "print('Confusion Matrix for Naive Bayes on ENN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_enn_nb))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_enn_nb))\n",
        "print(classification_report(y_test, y_pred_enn_nb))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_enn_nb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "Confusion Matrix for Naive Bayes on ENN Dataset\n",
            "[[84749   547]\n",
            " [   52    95]]\n",
            "Accuracy: 0.9929894783656941\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     85296\n",
            "           1       0.15      0.65      0.24       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.57      0.82      0.62     85443\n",
            "weighted avg       1.00      0.99      1.00     85443\n",
            "\n",
            "Kappa Score: 0.23867959938403982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "932c0639-971b-46f8-866d-3d8a94dd8417",
        "id": "gz7rBfr4Tace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "model=classifier.fit(X_train_cnn, y_train_cnn.ravel())\n",
        "y_pred_cnn_nb = model.predict(X_test)\n",
        "print (model)\n",
        "\n",
        "print('Confusion Matrix for Naive Bayes on CNN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_cnn_nb))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_cnn_nb))\n",
        "print(classification_report(y_test, y_pred_cnn_nb))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_cnn_nb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "Confusion Matrix for Naive Bayes on CNN Dataset\n",
            "[[84797   499]\n",
            " [   48    99]]\n",
            "Accuracy: 0.9935980712287724\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     85296\n",
            "           1       0.17      0.67      0.27       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.58      0.83      0.63     85443\n",
            "weighted avg       1.00      0.99      1.00     85443\n",
            "\n",
            "Kappa Score: 0.263738294339236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "14b84932-adf6-4357-9965-3d549aff7ca2",
        "id": "2o2qB8EcTamU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "model=classifier.fit(X_train_ncl, y_train_ncl.ravel())\n",
        "y_pred_ncl_nb = model.predict(X_test)\n",
        "print (model)\n",
        "\n",
        "print('Confusion Matrix for Naive Bayes on NCL Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_ncl_nb))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_ncl_nb))\n",
        "print(classification_report(y_test, y_pred_ncl_nb))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_ncl_nb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "Confusion Matrix for Naive Bayes on NCL Dataset\n",
            "[[84750   546]\n",
            " [   52    95]]\n",
            "Accuracy: 0.9930011820745994\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     85296\n",
            "           1       0.15      0.65      0.24       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.57      0.82      0.62     85443\n",
            "weighted avg       1.00      0.99      1.00     85443\n",
            "\n",
            "Kappa Score: 0.23898667617506708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1KBlyeCQYspa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'>RANDOM FOREST FOR UNDERBALANCED DATASETS</Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "TaOWtis8Yspb",
        "colab_type": "code",
        "outputId": "79026703-a690-4894-e62e-a776a67deca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
        "rfmod=rf.fit(X_train_rus50, y_train_rus50.ravel())\n",
        "y_pred_rus50_rf = rf.predict(X_test)\n",
        "print (rfmod)\n",
        "\n",
        "print('Confusion Matrix for Random Forest on RUS50 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus50_rf))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus50_rf))\n",
        "print(classification_report(y_test, y_pred_rus50_rf))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus50_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n",
            "Confusion Matrix for Random Forest on RUS50 Dataset\n",
            "[[83272  2024]\n",
            " [   16   131]]\n",
            "Accuracy: 0.9761244338330817\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     85296\n",
            "           1       0.06      0.89      0.11       147\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     85443\n",
            "   macro avg       0.53      0.93      0.55     85443\n",
            "weighted avg       1.00      0.98      0.99     85443\n",
            "\n",
            "Kappa Score: 0.11095030009147977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jz6sqlDUJk2u",
        "colab_type": "code",
        "outputId": "49730aaf-b8da-4460-9530-dfb04f4ecda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
        "rfmod=rf.fit(X_train_rus10, y_train_rus10.ravel())\n",
        "y_pred_rus10_rf = rf.predict(X_test)\n",
        "print (rfmod)\n",
        "\n",
        "print('Confusion Matrix for Random Forest on RUS10 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus10_rf))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus10_rf))\n",
        "print(classification_report(y_test, y_pred_rus10_rf))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus10_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n",
            "Confusion Matrix for Random Forest on RUS10 Dataset\n",
            "[[85216    80]\n",
            " [   22   125]]\n",
            "Accuracy: 0.9988062216916541\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.61      0.85      0.71       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.80      0.92      0.85     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.7096454231600258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m80iaVKtJh9s",
        "colab_type": "code",
        "outputId": "9e7c58b5-1206-4af3-c78d-201c97844dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
        "rfmod=rf.fit(X_train_rus1, y_train_rus1.ravel())\n",
        "y_pred_rus1_rf = rf.predict(X_test)\n",
        "print (rfmod)\n",
        "\n",
        "print('Confusion Matrix for Random Forest on RUS1 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus1_rf))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus1_rf))\n",
        "print(classification_report(y_test, y_pred_rus1_rf))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus1_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n",
            "Confusion Matrix for Random Forest on RUS1 Dataset\n",
            "[[85269    27]\n",
            " [   26   121]]\n",
            "Accuracy: 0.9993797034280163\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.82      0.82      0.82       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.91      0.91      0.91     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.8200283020071438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kplZ07YWJhgk",
        "colab_type": "code",
        "outputId": "fad37426-599c-4afe-8b92-cd6a43c0a231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
        "rfmod=rf.fit(X_train_enn, y_train_enn.ravel())\n",
        "y_pred_enn_rf = rf.predict(X_test)\n",
        "print (rfmod)\n",
        "\n",
        "print('Confusion Matrix for Random Forest on ENN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_enn_rf))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_enn_rf))\n",
        "print(classification_report(y_test, y_pred_enn_rf))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_enn_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n",
            "Confusion Matrix for Random Forest on ENN Dataset\n",
            "[[85290     6]\n",
            " [   35   112]]\n",
            "Accuracy: 0.9995201479348805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.95      0.76      0.85       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.97      0.88      0.92     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.8450456023772075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T9Uj2HOCJhH-",
        "colab_type": "code",
        "outputId": "30afc71d-8c1f-4cf0-e19d-c66f594264ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
        "rfmod=rf.fit(X_train_cnn, y_train_cnn.ravel())\n",
        "y_pred_cnn_rf = rf.predict(X_test)\n",
        "print (rfmod)\n",
        "\n",
        "print('Confusion Matrix for Random Forest on CNN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_cnn_rf))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_cnn_rf))\n",
        "print(classification_report(y_test, y_pred_cnn_rf))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_cnn_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n",
            "Confusion Matrix for Random Forest on CNN Dataset\n",
            "[[85183   113]\n",
            " [   24   123]]\n",
            "Accuracy: 0.9983965918799668\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.52      0.84      0.64       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.76      0.92      0.82     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.6415376255328962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E9BBOSCKJgvY",
        "colab_type": "code",
        "outputId": "f9294947-0f5b-4a47-c813-4eaa5b1bd632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
        "rfmod=rf.fit(X_train_ncl, y_train_ncl.ravel())\n",
        "y_pred_ncl_rf = rf.predict(X_test)\n",
        "print (rfmod)\n",
        "\n",
        "print('Confusion Matrix for Random Forest on NCL Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_ncl_rf))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_ncl_rf))\n",
        "print(classification_report(y_test, y_pred_ncl_rf))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_ncl_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n",
            "Confusion Matrix for Random Forest on NCL Dataset\n",
            "[[85291     5]\n",
            " [   39   108]]\n",
            "Accuracy: 0.9994850368081645\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.96      0.73      0.83       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.98      0.87      0.92     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.8305157732243474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FGLFwl5oYspo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'>DECISION TREE FOR UNDERBALANCED DATASETS</Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "8KIJgM8yYspp",
        "colab_type": "code",
        "outputId": "5a5f4d1d-fdc1-4b98-cf33-5b2a52dc402c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "decisionTreeClf = tree.DecisionTreeClassifier()\n",
        "decisionTreeClf = decisionTreeClf.fit(X_train_rus50, y_train_rus50.ravel())\n",
        "y_pred_rus50_dt = decisionTreeClf.predict(X_test)\n",
        "decisionTreeClf\n",
        "\n",
        "print('Confusion Matrix for Decision Tree on RUS50 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus50_dt))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus50_dt))\n",
        "print(classification_report(y_test, y_pred_rus50_dt))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus50_dt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Decision Tree on RUS50 Dataset\n",
            "[[79534  5762]\n",
            " [   21   126]]\n",
            "Accuracy: 0.9323174514003487\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96     85296\n",
            "           1       0.02      0.86      0.04       147\n",
            "\n",
            "   micro avg       0.93      0.93      0.93     85443\n",
            "   macro avg       0.51      0.89      0.50     85443\n",
            "weighted avg       1.00      0.93      0.96     85443\n",
            "\n",
            "Kappa Score: 0.038528687155860664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fey869IyYsps",
        "colab_type": "code",
        "outputId": "f58e2251-901d-47c9-cc85-5321f2f8819b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "decisionTreeClf = tree.DecisionTreeClassifier()\n",
        "decisionTreeClf = decisionTreeClf.fit(X_train_rus10, y_train_rus10.ravel())\n",
        "y_pred_rus10_dt = decisionTreeClf.predict(X_test)\n",
        "decisionTreeClf\n",
        "\n",
        "print('Confusion Matrix for Decision Tree on RUS10 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus10_dt))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus10_dt))\n",
        "print(classification_report(y_test, y_pred_rus10_dt))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus10_dt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Decision Tree on RUS10 Dataset\n",
            "[[83840  1456]\n",
            " [   21   126]]\n",
            "Accuracy: 0.9827136219467949\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     85296\n",
            "           1       0.08      0.86      0.15       147\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     85443\n",
            "   macro avg       0.54      0.92      0.57     85443\n",
            "weighted avg       1.00      0.98      0.99     85443\n",
            "\n",
            "Kappa Score: 0.14305101673986997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "scu0rL46Yspv",
        "colab_type": "code",
        "outputId": "f5cc6e05-9bd1-4240-e1c8-47892fb31046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "decisionTreeClf = tree.DecisionTreeClassifier()\n",
        "decisionTreeClf = decisionTreeClf.fit(X_train_rus1, y_train_rus1.ravel())\n",
        "y_pred_rus1_dt = decisionTreeClf.predict(X_test)\n",
        "decisionTreeClf\n",
        "\n",
        "print('Confusion Matrix for Decision Tree on RUS1 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus1_dt))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus1_dt))\n",
        "print(classification_report(y_test, y_pred_rus1_dt))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus1_dt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Decision Tree on RUS1 Dataset\n",
            "[[85147   149]\n",
            " [   28   119]]\n",
            "Accuracy: 0.9979284435237527\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.44      0.81      0.57       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.72      0.90      0.79     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.5725441394901246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xNWSHBrmYspx",
        "colab_type": "code",
        "outputId": "d0758318-016e-4f1f-8a74-13da40a3c5cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "decisionTreeClf = tree.DecisionTreeClassifier()\n",
        "decisionTreeClf = decisionTreeClf.fit(X_train_enn, y_train_enn.ravel())\n",
        "y_pred_enn_dt = decisionTreeClf.predict(X_test)\n",
        "decisionTreeClf\n",
        "\n",
        "print('Confusion Matrix for Decision Tree on ENN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_enn_dt))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_enn_dt))\n",
        "print(classification_report(y_test, y_pred_enn_dt))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_enn_dt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Decision Tree on ENN Dataset\n",
            "[[85265    31]\n",
            " [   38   109]]\n",
            "Accuracy: 0.9991924440855307\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.78      0.74      0.76       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.89      0.87      0.88     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.7591776653067948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PylJyl6eYspz",
        "colab_type": "code",
        "outputId": "6cb76297-9e75-49af-d092-32451578de2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "decisionTreeClf = tree.DecisionTreeClassifier()\n",
        "decisionTreeClf = decisionTreeClf.fit(X_train_cnn, y_train_cnn.ravel())\n",
        "y_pred_cnn_dt = decisionTreeClf.predict(X_test)\n",
        "decisionTreeClf\n",
        "\n",
        "print('Confusion Matrix for Decision Tree on CNN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_cnn_dt))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_cnn_dt))\n",
        "print(classification_report(y_test, y_pred_cnn_dt))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_cnn_dt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Decision Tree on CNN Dataset\n",
            "[[83216  2080]\n",
            " [   22   125]]\n",
            "Accuracy: 0.9753988038809499\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     85296\n",
            "           1       0.06      0.85      0.11       147\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     85443\n",
            "   macro avg       0.53      0.91      0.55     85443\n",
            "weighted avg       1.00      0.98      0.99     85443\n",
            "\n",
            "Kappa Score: 0.10340023431052381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o2m6XKrhLz07",
        "colab_type": "code",
        "outputId": "9b3328cd-f4d0-4443-b94c-71813af8b66d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "decisionTreeClf = tree.DecisionTreeClassifier()\n",
        "decisionTreeClf = decisionTreeClf.fit(X_train_ncl, y_train_ncl.ravel())\n",
        "y_pred_ncl_dt = rf.predict(X_test)\n",
        "decisionTreeClf\n",
        "\n",
        "print('Confusion Matrix for Decision Tree on NCL Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_ncl_dt))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_ncl_dt))\n",
        "print(classification_report(y_test, y_pred_ncl_dt))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_ncl_dt))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Decision Tree on NCL Dataset\n",
            "[[85291     5]\n",
            " [   39   108]]\n",
            "Accuracy: 0.9994850368081645\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.96      0.73      0.83       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.98      0.87      0.92     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.8305157732243474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HNsp0cWRYsp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'>NEURAL NETWORK (MLP) FOR UNDERBALANCED DATASETS</Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "bOc5LdeYYsp2",
        "colab_type": "code",
        "outputId": "1c6f570e-f27c-4bc5-d792-68d975e4cb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(8,7), max_iter=8)  \n",
        "mlp.fit(X_train_rus50, y_train_rus50.ravel())  \n",
        "y_pred_rus50_mlp = mlp.predict(X_test)\n",
        "mlp\n",
        "\n",
        "print('Confusion Matrix for Neural Networks on RUS50 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus50_mlp))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus50_mlp))\n",
        "print(classification_report(y_test, y_pred_rus50_mlp))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus50_mlp))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Neural Networks on RUS50 Dataset\n",
            "[[85296     0]\n",
            " [  147     0]]\n",
            "Accuracy: 0.9982795547909132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.00      0.00      0.00       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.50      0.50      0.50     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qqbH9ngKYsp7",
        "colab_type": "code",
        "outputId": "e8634210-a435-4dc9-d904-73a42fcbf89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(8,7), max_iter=8)  \n",
        "mlp.fit(X_train_rus10, y_train_rus10.ravel())  \n",
        "y_pred_rus10_mlp = mlp.predict(X_test)\n",
        "mlp\n",
        "\n",
        "print('Confusion Matrix for Neural Networks on RUS10 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus10_mlp))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus10_mlp))\n",
        "print(classification_report(y_test, y_pred_rus10_mlp))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus10_mlp))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Neural Networks on RUS10 Dataset\n",
            "[[85296     0]\n",
            " [  147     0]]\n",
            "Accuracy: 0.9982795547909132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.00      0.00      0.00       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.50      0.50      0.50     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oTKv4FKCYsp8",
        "colab_type": "code",
        "outputId": "11a28f7d-d9e1-4710-a4e0-9d4ffe6cbb31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(8,7), max_iter=8)  \n",
        "mlp.fit(X_train_rus1, y_train_rus1.ravel())  \n",
        "y_pred_rus1_mlp = mlp.predict(X_test)\n",
        "mlp\n",
        "\n",
        "print('Confusion Matrix for Neural Networks on RUS1 Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_rus1_mlp))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus1_mlp))\n",
        "print(classification_report(y_test, y_pred_rus1_mlp))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus1_mlp))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Neural Networks on RUS1 Dataset\n",
            "[[85296     0]\n",
            " [  147     0]]\n",
            "Accuracy: 0.9982795547909132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.00      0.00      0.00       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.50      0.50      0.50     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pz82pDhjYsp-",
        "colab_type": "code",
        "outputId": "eb2c59e2-0665-47a6-cccd-1a45cdc75a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(8,7), max_iter=8)  \n",
        "mlp.fit(X_train_enn, y_train_enn.ravel())  \n",
        "y_pred_enn_mlp = mlp.predict(X_test)\n",
        "mlp\n",
        "\n",
        "print('Confusion Matrix for Neural Networks on ENN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_enn_mlp))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_enn_mlp))\n",
        "print(classification_report(y_test, y_pred_enn_mlp))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_enn_mlp))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Neural Networks on ENN Dataset\n",
            "[[84678   618]\n",
            " [  145     2]]\n",
            "Accuracy: 0.9910700701052163\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     85296\n",
            "           1       0.00      0.01      0.01       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.50      0.50      0.50     85443\n",
            "weighted avg       1.00      0.99      0.99     85443\n",
            "\n",
            "Kappa Score: 0.0024404880847637145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BZQsxeTAYsqB",
        "colab_type": "code",
        "outputId": "8b28beb9-ca78-4a42-b088-5cd81e766daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(8,7), max_iter=8)  \n",
        "mlp.fit(X_train_cnn, y_train_cnn.ravel())  \n",
        "y_pred_cnn_mlp = mlp.predict(X_test)\n",
        "mlp\n",
        "\n",
        "print('Confusion Matrix for Neural Networks on CNN Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_cnn_mlp))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_cnn_mlp))\n",
        "print(classification_report(y_test, y_pred_cnn_mlp))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_cnn_mlp))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Neural Networks on CNN Dataset\n",
            "[[85296     0]\n",
            " [  147     0]]\n",
            "Accuracy: 0.9982795547909132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.00      0.00      0.00       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.50      0.50      0.50     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hHbX0WO7YsqC",
        "colab_type": "code",
        "outputId": "a8fc1543-55ef-460a-f714-c269f0da2c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(8,7), max_iter=8)  \n",
        "mlp.fit(X_train_ncl, y_train_ncl.ravel())  \n",
        "y_pred_ncl_mlp = mlp.predict(X_test)\n",
        "mlp\n",
        "\n",
        "print('Confusion Matrix for Neural Networks on NCL Dataset')\n",
        "print(confusion_matrix(y_test, y_pred_ncl_mlp))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_ncl_mlp))\n",
        "print(classification_report(y_test, y_pred_ncl_mlp))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_ncl_mlp))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Neural Networks on NCL Dataset\n",
            "[[85296     0]\n",
            " [  147     0]]\n",
            "Accuracy: 0.9982795547909132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.00      0.00      0.00       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.50      0.50      0.50     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "q_oxs6eTYsqE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><Bold><font size ='+2'>LOGISTIC REGRESSION FOR UNDERBALANCED DATASETS</Bold></center></font>"
      ]
    },
    {
      "metadata": {
        "id": "aSR0aG7TYsqE",
        "colab_type": "code",
        "outputId": "a7064e87-f819-41d9-d730-36efbb0ff311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train_rus50, y_train_rus50)\n",
        "y_pred_rus50_lr = clf.predict(X_test)\n",
        "print(clf)\n",
        "\n",
        "print('Confusion Matrix for Linear Regression on RUS50')\n",
        "print(confusion_matrix(y_test, y_pred_rus50_lr))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus50_lr))\n",
        "print(classification_report(y_test, y_pred_rus50_lr))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus50_lr))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
            "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "Confusion Matrix for Linear Regression on RUS50\n",
            "[[81058  4238]\n",
            " [   18   129]]\n",
            "Accuracy: 0.9501890148988215\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97     85296\n",
            "           1       0.03      0.88      0.06       147\n",
            "\n",
            "   micro avg       0.95      0.95      0.95     85443\n",
            "   macro avg       0.51      0.91      0.52     85443\n",
            "weighted avg       1.00      0.95      0.97     85443\n",
            "\n",
            "Kappa Score: 0.05400645823755579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SEmRmU44YsqG",
        "colab_type": "code",
        "outputId": "b7158761-beca-4af3-f2b2-c55efff7a38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train_rus10, y_train_rus10)\n",
        "y_pred_rus10_lr = clf.predict(X_test)\n",
        "print(clf)\n",
        "\n",
        "print('Confusion Matrix for Linear Regression on RUS10')\n",
        "print(confusion_matrix(y_test, y_pred_rus10_lr))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus10_lr))\n",
        "print(classification_report(y_test, y_pred_rus10_lr))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus10_lr))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
            "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "Confusion Matrix for Linear Regression on RUS10\n",
            "[[84604   692]\n",
            " [   21   126]]\n",
            "Accuracy: 0.991655255550484\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     85296\n",
            "           1       0.15      0.86      0.26       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.58      0.92      0.63     85443\n",
            "weighted avg       1.00      0.99      0.99     85443\n",
            "\n",
            "Kappa Score: 0.25897853382796177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AfXTDpO-YsqI",
        "colab_type": "code",
        "outputId": "7fc621dc-28d2-41bc-f3e0-b338112adcb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train_rus1, y_train_rus1)\n",
        "y_pred_rus1_lr = clf.predict(X_test)\n",
        "print(clf)\n",
        "\n",
        "print('Confusion Matrix for Linear Regression on RUS1')\n",
        "print(confusion_matrix(y_test, y_pred_rus1_lr))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_rus1_lr))\n",
        "print(classification_report(y_test, y_pred_rus1_lr))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_rus1_lr))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
            "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "Confusion Matrix for Linear Regression on RUS1\n",
            "[[85175   121]\n",
            " [   28   119]]\n",
            "Accuracy: 0.9982561473731025\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.50      0.81      0.61       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.75      0.90      0.81     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.6141637497116685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o7u0Gj_ASW0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "efe00e07-b874-4dca-f5ee-680e1a032df7"
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train_enn, y_train_enn)\n",
        "y_pred_enn_lr = clf.predict(X_test)\n",
        "print(clf)\n",
        "\n",
        "print('Confusion Matrix for Linear Regression on ENN')\n",
        "print(confusion_matrix(y_test, y_pred_enn_lr))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_enn_lr))\n",
        "print(classification_report(y_test, y_pred_enn_lr))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_enn_lr))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
            "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "Confusion Matrix for Linear Regression on ENN\n",
            "[[85262    34]\n",
            " [   52    95]]\n",
            "Accuracy: 0.9989934810341398\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.74      0.65      0.69       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.87      0.82      0.84     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.6879038709172676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gtWlyI7ZSX3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "49d2d246-1ff9-4c4f-a821-71b208773471"
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train_cnn, y_train_cnn)\n",
        "y_pred_cnn_lr = clf.predict(X_test)\n",
        "print(clf)\n",
        "\n",
        "print('Confusion Matrix for Linear Regression on CNN')\n",
        "print(confusion_matrix(y_test, y_pred_cnn_lr))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_cnn_lr))\n",
        "print(classification_report(y_test, y_pred_cnn_lr))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_cnn_lr))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
            "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "Confusion Matrix for Linear Regression on CNN\n",
            "[[84444   852]\n",
            " [   23   124]]\n",
            "Accuracy: 0.9897592547078169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     85296\n",
            "           1       0.13      0.84      0.22       147\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     85443\n",
            "   macro avg       0.56      0.92      0.61     85443\n",
            "weighted avg       1.00      0.99      0.99     85443\n",
            "\n",
            "Kappa Score: 0.21849998345799426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1qM1SoNoSXiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "288d89ac-47a1-4eae-8c0b-8215589dad15"
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train_ncl, y_train_ncl)\n",
        "y_pred_ncl_lr = clf.predict(X_test)\n",
        "print(clf)\n",
        "\n",
        "print('Confusion Matrix for Linear Regression on NCL')\n",
        "print(confusion_matrix(y_test, y_pred_ncl_lr))  \n",
        "print ('Accuracy:', accuracy_score(y_test, y_pred_ncl_lr))\n",
        "print(classification_report(y_test, y_pred_ncl_lr))\n",
        "print ('Kappa Score:', cohen_kappa_score(y_test, y_pred_ncl_lr))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
            "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "Confusion Matrix for Linear Regression on NCL\n",
            "[[85262    34]\n",
            " [   49    98]]\n",
            "Accuracy: 0.9990285921608558\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85296\n",
            "           1       0.74      0.67      0.70       147\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     85443\n",
            "   macro avg       0.87      0.83      0.85     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "Kappa Score: 0.7020238708838973\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}